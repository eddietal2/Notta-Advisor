# Gemi Chat ğŸ¤–

A CLI-based AI chatbot for analyzing UBER SEC 10-K filings using Retrieval-Augmented Generation (RAG) and Google's Gemini API.

## ğŸš€ Features

- **AI-Powered Analysis**: Interactive chat with a FunctionAgent that answers questions about UBER's financial data from 2019-2022.
- **RAG with LlamaIndex**: Indexes SEC filings for accurate, context-aware responses.
- **CLI Interface**: Simple command-line tools for data loading and chatting.
- **Modular Design**: Clean, maintainable code structure for easy extension.

## ğŸ“¦ Installation

1. **Clone the repo**:
   ```bash
   git clone https://github.com/yourusername/gemi-chat.git
   cd gemi-chat
   ```

2. **Install dependencies** (using uv for speed):
   ```bash
   uv sync
   ```

3. **Set up environment**:
   - Create a `.env` file: `GOOGLE_API_KEY=your_gemini_api_key`
   - Or set the env var: `$env:GOOGLE_API_KEY = "your_key"`

## ğŸ› ï¸ Usage

- **Load and index data**:
  ```bash
  python -m src.cli --load-data
  ```

- **Start interactive chat**:
  ```bash
  python -m src.cli --chat
  ```

- **View help**:
  ```bash
  python -m src.cli --help
  ```

Example chat: Ask questions like "What were UBER's revenue trends in 2020?" and get AI-powered answers based on the filings.

## ğŸ“ Project Structure

```
Gemi_Chat/
â”œâ”€â”€ src/                          # Main package
â”‚   â”œâ”€â”€ __init__.py              # Package init
â”‚   â”œâ”€â”€ config.py                # Settings & env vars
â”‚   â”œâ”€â”€ data_loader.py           # Loads UBER HTML data
â”‚   â”œâ”€â”€ index_manager.py         # Manages vector indices
â”‚   â”œâ”€â”€ ageny.py                 # AI agent & tools
â”‚   â”œâ”€â”€ cli.py                   # Command-line interface
â”‚   â”œâ”€â”€ custom_console.py        # Console utilities
â”‚   â””â”€â”€ google_llm_init.py       # Gemini LLM setup
â”œâ”€â”€ pyproject.toml               # Project config & deps
â”œâ”€â”€ system_prompt.txt            # Agent system prompt
â”œâ”€â”€ .env                         # Environment variables
â”œâ”€â”€ data/UBER/                   # UBER SEC filings
â””â”€â”€ storage/                     # Persisted indices
```

### Module Details

- **`config.py`**: Centralized configuration (years, paths, API keys).
- **`data_loader.py`**: Data ingestion with UnstructuredReader.
- **`index_manager.py`**: Vector index creation/persistence.
- **`ageny.py`**: Agent setup with query engines and chat loop.
- **`cli.py`**: CLI with argparse for commands.
- **`custom_console.py`**: Spinners, colors, timers.
- **`google_llm_init.py`**: Google Gemini LLM initialization.

## ğŸ—ï¸ Architecture

The CLI_Chat application follows a modular RAG (Retrieval-Augmented Generation) architecture:

### System Overview
```
CLI Interface â†’ Data Processing â†’ Vector Indexing â†’ AI Agent â†’ Chat Interface
```

### Core Components Flow
1. **Data Pipeline**: HTML SEC filings â†’ Document parsing â†’ Vector embeddings â†’ Persistent storage
2. **Query Pipeline**: User question â†’ Index retrieval â†’ Context augmentation â†’ LLM generation â†’ Response
3. **Agent System**: FunctionAgent with specialized tools for multi-year financial analysis

### Architecture Diagrams
- **[Detailed Component Diagram](architecture_diagram.md)**: Complete system architecture with all modules and dependencies
- **[Process Flow Diagram](flow_diagram.md)**: High-level user journey and data flow

### Key Technologies
- **LlamaIndex**: Vector indexing, query engines, and agent framework
- **Google Gemini**: LLM for generation and embeddings for semantic search
- **Unstructured.io**: Document parsing for HTML SEC filings
- **RAG Pattern**: Retrieval-augmented generation for accurate financial analysis

## ğŸ¤ Contributing

1. Fork the repo.
2. Create a feature branch.
3. Commit changes.
4. Push and open a PR.

## ğŸ“„ License

MIT License - see LICENSE file for details.

## âš ï¸ Disclaimer

This is for educational purposes only. Not financial advice.